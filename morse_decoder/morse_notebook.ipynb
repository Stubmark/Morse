{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, Conv1D, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras, config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \", len(config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "image_target_size = (5, 1400, 1)\n",
    "batch_size =  128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from morse_helpers import create_sets\n",
    "from morse_label_funcs import  labels_to_one_hot_positions_categorical, letter_n_to_one_hot_positions_categorical, position_regression\n",
    "\n",
    "(image_fnames, morse_labels) = create_sets(\n",
    "    [\n",
    "        [\"./training_data/MorseTrainSet_04/GEN04_VER_000/\", 'wordsMatrices_04_000', \"Words_04_000.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_04/GEN04_VER_100/\", 'wordsMatrices_04_100', \"Words_04_100.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_04/GEN04_VER_200/\", 'wordsMatrices_04_200', \"Words_04_200.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_04/GEN04_VER_210/\", 'wordsMatrices_04_210', \"Words_04_210.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_04/GEN04_VER_220/\", 'wordsMatrices_04_220', \"Words_04_220.csv\"],\n",
    "\n",
    "        [\"./training_data/MorseTrainSet_11/GEN11_VER_000/\", 'wordsMatrices_11_000', \"Words_11_000.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_11/GEN11_VER_100/\", 'wordsMatrices_11_100', \"Words_11_100.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_11/GEN11_VER_200/\", 'wordsMatrices_11_200', \"Words_11_200.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_11/GEN11_VER_210/\", 'wordsMatrices_11_210', \"Words_11_210.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_11/GEN11_VER_220/\", 'wordsMatrices_11_220', \"Words_11_220.csv\"],\n",
    "\n",
    "    ], \n",
    "    image_target_size,\n",
    "    position_regression,\n",
    "    letter_n=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import unison_shuffle, round_to_100, data_slice, data_set_create\n",
    "\n",
    "test_split_size = 0.90\n",
    "validation_split_size = 0.90\n",
    "\n",
    "\n",
    "def create_all_sets(train, labels, shuffle_before_test_split=True):\n",
    "\n",
    "    if shuffle_before_test_split == True:\n",
    "        # shuffle data\n",
    "        train, labels = unison_shuffle(train, labels)\n",
    "    \n",
    "    # get test slice\n",
    "    train, train_test, labels, labels_test = data_set_create(train, labels, test_split_size)\n",
    "\n",
    "    if shuffle_before_test_split == False:\n",
    "        # shuffle data\n",
    "        train, labels = unison_shuffle(train, labels)\n",
    "\n",
    "    # get validation slice\n",
    "    train, train_validation, labels, labels_validation = data_set_create(train, labels, validation_split_size)\n",
    "\n",
    "    return train, labels, train_validation, labels_validation, train_test, labels_test\n",
    "\n",
    "train, labels, train_validation, labels_validation, train_test, labels_test = create_all_sets(image_fnames, morse_labels, shuffle_before_test_split=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import Image_Generator, zeropad_randomly\n",
    "\n",
    "training_batch_generator = Image_Generator(train, labels, batch_size, image_target_size, [zeropad_randomly])\n",
    "validation_batch_generator = Image_Generator(train_validation, labels_validation, batch_size, image_target_size, [zeropad_randomly])\n",
    "test_batch_generator = Image_Generator(train_test, labels_test, batch_size, image_target_size, [])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, l = test_batch_generator.__getitem__(0)\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(l[i] * 1400)\n",
    "#     fig = plt.figure(figsize=(30,5))\n",
    "#     plt.xlim(0, 800)\n",
    "#     rolled = np.pad(t[i], [(0,0),(0,0), (0,0)], mode='constant')[:, 0:-1]\n",
    "#     rolled[:, int(l[i] * 1400)] = 1\n",
    "#     plt.imshow(rolled)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer     = Input(shape=image_target_size)\n",
    "cropped = keras.layers.Cropping2D(cropping=((0, 0), (0,1000)), data_format=None)(input_layer)\n",
    "pool           = MaxPooling2D(pool_size=(2,2),padding=\"same\")(cropped)\n",
    "\n",
    "conv1           = Conv2D(80,(3,5),padding=\"same\",activation=\"relu\")(pool)\n",
    "pool1           = MaxPooling2D(pool_size=(2,2),padding=\"same\")(conv1)\n",
    "\n",
    "conv2           = Conv2D(80,(1,7),padding=\"same\",activation=\"relu\")(pool1)\n",
    "pool2           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv2)\n",
    "\n",
    "conv3           = Conv2D(80,(1,11),padding=\"same\",activation=\"relu\")(pool2)\n",
    "pool3           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv3)\n",
    "\n",
    "conv4           = Conv2D(80,(1,13),padding=\"same\",activation=\"relu\")(pool3)\n",
    "pool4           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv4)\n",
    "\n",
    "conv5           = Conv2D(80,(1,11),padding=\"same\",activation=\"relu\")(pool4)\n",
    "pool5           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv5)\n",
    "\n",
    "conv6           = Conv2D(80,(1,9),padding=\"same\",activation=\"relu\")(pool5)\n",
    "pool6           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv6)\n",
    "\n",
    "conv7           = Conv2D(80,(1,5),padding=\"same\",activation=\"relu\")(pool6)\n",
    "pool7           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv7)\n",
    "\n",
    "flat            = Flatten()(pool7)\n",
    "\n",
    "output_layer    = Dense(1)(flat)\n",
    "model           = Model(inputs=input_layer, outputs=output_layer)\n",
    "print(model.summary())\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 25\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = model.fit_generator(generator = training_batch_generator,\n",
    "\t                   steps_per_epoch = int(len(train) // batch_size),\n",
    "\t                   epochs = epochs + init_epoch,\n",
    "\t\t\t\t\t   initial_epoch=init_epoch,\n",
    "\t                   verbose =1,\n",
    "\t                   validation_data = validation_batch_generator,\n",
    "\t                   validation_steps = int(len(train_validation) // batch_size))\n",
    "\t\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf as mpt\n",
    "\n",
    "raw_predictions = model.predict_generator(generator=test_batch_generator)\n",
    "\n",
    "print(raw_predictions[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def right_roll_image_by_n(img, roll_value_n):\n",
    "    return np.roll(img, roll_value_n, axis=1)\n",
    "\n",
    "def get_label_prediction(img, model): \n",
    "    x_right_rolled_exp_dim = np.expand_dims(img, axis=0)\n",
    "    single_predict = model.predict(x_right_rolled_exp_dim)\n",
    "    return single_predict[0] * image_target_size[1]\n",
    "\n",
    "def show_image(img):\n",
    "    fig = plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, 400)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def roll_and_display_img(img, indexer, display=False):\n",
    "\n",
    "    image_right_rolled = right_roll_image_by_n(img, int(-10 + (indexer / 5)))\n",
    "\n",
    "    label_prediction = get_label_prediction(image_right_rolled, model)\n",
    "\n",
    "    # Draw vertical line\n",
    "    image_right_rolled[:, int(label_prediction)] = 1\n",
    "\n",
    "    if display:    \n",
    "        fig = show_image(image_right_rolled)\n",
    "        pdf.savefig( fig )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mpt.PdfPages(\"single_predictions_rolled_randomly.pdf\")\n",
    "\n",
    "single_image_batch, single_label_batch = test_batch_generator.__getitem__(0)\n",
    "\n",
    "for i in range(len(single_image_batch)):\n",
    "    roll_and_display_img(single_image_batch[i], i, display=False)\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def get_deviating_predictions(above_pixels):\n",
    "    regression_differences = []\n",
    "    indexer = 0\n",
    "\n",
    "    for data_name_gen, label_names_gen in test_batch_generator:\n",
    "\n",
    "        for i in range(len(data_name_gen)):\n",
    "\n",
    "            pred = raw_predictions[indexer] * image_target_size[1]\n",
    "            test_label = label_names_gen[i] * image_target_size[1]\n",
    "\n",
    "            diff =  abs(pred - test_label) > above_pixels\n",
    "            if (diff == True):\n",
    "                a = [pred, test_label, data_name_gen[i]]\n",
    "                regression_differences.append(a)\n",
    "\n",
    "            indexer += 1\n",
    "\n",
    "    return regression_differences\n",
    "\n",
    "above_pixels = 3\n",
    "\n",
    "deviating_predictions = get_deviating_predictions(above_pixels=above_pixels)\n",
    "\n",
    "print(\"Total predictions\", len(raw_predictions))\n",
    "print(\"Total predictions off by more than pixels\", above_pixels, \" : \", len(deviating_predictions))\n",
    "print(\"Percentage incorrect\", round( (len(deviating_predictions) / len(raw_predictions) * 100), 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0   \n",
    "for diff in deviating_predictions:\n",
    "\n",
    "    counter += 1\n",
    "    if counter > 30:\n",
    "        break\n",
    "\n",
    "    pred, correct, img = diff\n",
    "\n",
    "    img_pred = img.copy()\n",
    "    img_correct = img.copy()\n",
    "\n",
    "    print('Prediction', pred)\n",
    "    img_pred[:, int(pred)] = 1\n",
    "    show_image(img_pred)\n",
    "\n",
    "    print('Correct', correct)\n",
    "    img_correct[:, int(correct)] = 1\n",
    "    show_image(img_correct)\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddce95701716284d8751d5796858f7ca5e76f20d028bc4aeb8f12865d04c55c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('newenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
